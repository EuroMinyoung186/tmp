24-09-22 17:23:21.416 - INFO:   name: train_editguard
  use_tb_logger: True
  model: MIMO-VRN-h
  distortion: sr
  scale: 4
  gpu_ids: [0, 1, 2, 3]
  gop: 1
  num_image: 1
  addnoise: True
  noisesigma: 10
  add_downsampling: True
  downsample_size: 256
  add_upsampling: True
  upsample_size: 1024
  addjpeg: True
  addSampling: True
  jpegfactor: 90
  addpossion: True
  sdinpaint: False
  controlnetinpaint: False
  sdxl: False
  repaint: False
  num_noise: 5
  hide: True
  bithide: False
  degrade_shuffle: True
  prompt: True
  prompt_len: 5
  message_length: 64
  losstype: mse
  mode: image
  datasets:[
    train:[
      name: CoCo
      mode: train
      interval_list: [1]
      random_reverse: False
      border_mode: False
      data_path: /home/aikusrv02/editguard/EditGuard/dataset/train2017
      txt_path: /home/aikusrv02/editguard/EditGuardChange/dataset/train2017.txt
      dataroot_LQ: /home/aikusrv02/vimeo90k/vimeo90k_train_LR7frames.lmdb
      cache_keys: Vimeo90K_train_keys.pkl
      num_image: 1
      N_frames: 1
      use_shuffle: True
      n_workers: 8
      batch_size: 4
      GT_size: 400
      LQ_size: 36
      use_flip: True
      use_rot: True
      color: RGB
      phase: train
      scale: 4
      data_type: lmdb
    ]
    val:[
      num_image: 1
      name: CoCo
      mode: test
      data_path: /home/aikusrv02/editguard/EditGuardChange/dataset/valAGE-Set
      txt_path: /home/aikusrv02/editguard/EditGuardChange/dataset/sep_vallist.txt
      N_frames: 1
      padding: new_info
      pred_interval: -1
      phase: val
      scale: 4
      data_type: img
    ]
  ]
  network_G:[
    which_model_G:[
      subnet_type: DBNet
    ]
    in_nc: 12
    out_nc: 12
    block_num: [6, 6]
    scale: 4
    init: xavier_group
    block_num_rbm: 8
    block_num_trans: 4
  ]
  path:[
    pretrain_model_G: None
    models: /home/aikusrv02/editguard/EditGuardChange/experiments/train_editguard/models
    strict_load: False
    resume_state: None
    root: /home/aikusrv02/editguard/EditGuardChange
    experiments_root: /home/aikusrv02/editguard/EditGuardChange/experiments/train_editguard
    training_state: /home/aikusrv02/editguard/EditGuardChange/experiments/train_editguard/training_state
    log: /home/aikusrv02/editguard/EditGuardChange/experiments/train_editguard
    val_images: /home/aikusrv02/editguard/EditGuardChange/experiments/train_editguard/val_images
  ]
  train:[
    lr_G: 0.0001
    beta1: 0.9
    beta2: 0.5
    niter: 250000
    warmup_iter: -1
    lr_scheme: MultiStepLR
    lr_steps: [30000, 60000, 90000, 150000, 180000, 210000]
    lr_gamma: 0.5
    pixel_criterion_forw: l2
    pixel_criterion_back: l1
    manual_seed: 10
    val_freq: 100.0
    lambda_fit_forw: 100
    lambda_rec_back: 1
    lambda_center: 0
    weight_decay_G: 1e-12
    gradient_clipping: 10
  ]
  logger:[
    print_freq: 100
    save_checkpoint_freq: 500.0
  ]
  is_train: True
  dist: False

24-09-22 17:23:21.558 - INFO: Random seed: 10
24-09-22 17:23:21.589 - INFO: Temporal augmentation interval list: [1], with random reverse is False.
24-09-22 17:23:21.645 - INFO: Dataset [CoCoDataset - CoCo] is created.
24-09-22 17:23:21.646 - INFO: Number of train images: 118,287, iters: 29,572
24-09-22 17:23:21.646 - INFO: Total epochs needed: 9 for iters 250,000
24-09-22 17:23:21.646 - INFO: Dataset [imageTestDataset - CoCo] is created.
24-09-22 17:23:21.646 - INFO: Number of val images in [CoCo]: 100
24-09-22 17:23:25.052 - INFO: Network G structure: DataParallel - VSN, with parameters: 9,357,893
24-09-22 17:23:25.052 - INFO: VSN(
  (bitencoder): DW_Encoder(
    (conv1): ConvBlock(
      (layers): Sequential(
        (0): ConvINRelu(
          (layers): Sequential(
            (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
          )
        )
        (1): ConvINRelu(
          (layers): Sequential(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
          )
        )
      )
    )
    (down1): Down(
      (layer): Sequential(
        (0): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
        (1): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
            (1): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    (down2): Down(
      (layer): Sequential(
        (0): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
        (1): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
            (1): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    (down3): Down(
      (layer): Sequential(
        (0): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
        (1): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
            (1): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    (down4): Down(
      (layer): Sequential(
        (0): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
        (1): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
            (1): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    (up3): UP(
      (conv): ConvBlock(
        (layers): Sequential(
          (0): ConvINRelu(
            (layers): Sequential(
              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): ReLU(inplace=True)
            )
          )
        )
      )
    )
    (linear3): Linear(in_features=64, out_features=4096, bias=True)
    (Conv_message3): ConvBlock(
      (layers): Sequential(
        (0): ConvINRelu(
          (layers): Sequential(
            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
          )
        )
        (1): ConvINRelu(
          (layers): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
          )
        )
      )
    )
    (att3): ResBlock(
      (layers): Sequential(
        (0): BottleneckBlock(
          (change): Sequential(
            (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (left): Sequential(
            (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (1): BottleneckBlock(
          (left): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
      )
    )
    (up2): UP(
      (conv): ConvBlock(
        (layers): Sequential(
          (0): ConvINRelu(
            (layers): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): ReLU(inplace=True)
            )
          )
        )
      )
    )
    (linear2): Linear(in_features=64, out_features=4096, bias=True)
    (Conv_message2): ConvBlock(
      (layers): Sequential(
        (0): ConvINRelu(
          (layers): Sequential(
            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
          )
        )
        (1): ConvINRelu(
          (layers): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
          )
        )
      )
    )
    (att2): ResBlock(
      (layers): Sequential(
        (0): BottleneckBlock(
          (change): Sequential(
            (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (left): Sequential(
            (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (1): BottleneckBlock(
          (left): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
      )
    )
    (up1): UP(
      (conv): ConvBlock(
        (layers): Sequential(
          (0): ConvINRelu(
            (layers): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): ReLU(inplace=True)
            )
          )
        )
      )
    )
    (linear1): Linear(in_features=64, out_features=4096, bias=True)
    (Conv_message1): ConvBlock(
      (layers): Sequential(
        (0): ConvINRelu(
          (layers): Sequential(
            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
          )
        )
        (1): ConvINRelu(
          (layers): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
          )
        )
      )
    )
    (att1): ResBlock(
      (layers): Sequential(
        (0): BottleneckBlock(
          (change): Sequential(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (left): Sequential(
            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (1): BottleneckBlock(
          (left): Sequential(
            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
      )
    )
    (up0): UP(
      (conv): ConvBlock(
        (layers): Sequential(
          (0): ConvINRelu(
            (layers): Sequential(
              (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): ReLU(inplace=True)
            )
          )
        )
      )
    )
    (linear0): Linear(in_features=64, out_features=4096, bias=True)
    (Conv_message0): ConvBlock(
      (layers): Sequential(
        (0): ConvINRelu(
          (layers): Sequential(
            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
          )
        )
        (1): ConvINRelu(
          (layers): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
          )
        )
      )
    )
    (att0): ResBlock(
      (layers): Sequential(
        (0): BottleneckBlock(
          (change): Sequential(
            (0): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (left): Sequential(
            (0): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (1): BottleneckBlock(
          (left): Sequential(
            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
      )
    )
    (Conv_1x1): Conv2d(19, 3, kernel_size=(1, 1), stride=(1, 1))
  )
  (bitdecoder): DW_Decoder(
    (conv1): ConvBlock(
      (layers): Sequential(
        (0): ConvINRelu(
          (layers): Sequential(
            (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
          )
        )
        (1): ConvINRelu(
          (layers): Sequential(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
          )
        )
      )
    )
    (down1): Down(
      (layer): Sequential(
        (0): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
        (1): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
            (1): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    (down2): Down(
      (layer): Sequential(
        (0): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
        (1): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
            (1): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    (down3): Down(
      (layer): Sequential(
        (0): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
        (1): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
            (1): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    (down4): Down(
      (layer): Sequential(
        (0): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
        (1): ConvBlock(
          (layers): Sequential(
            (0): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
            (1): ConvINRelu(
              (layers): Sequential(
                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    (up3): UP(
      (conv): ConvBlock(
        (layers): Sequential(
          (0): ConvINRelu(
            (layers): Sequential(
              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): ReLU(inplace=True)
            )
          )
        )
      )
    )
    (att3): ResBlock(
      (layers): Sequential(
        (0): BottleneckBlock(
          (change): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (left): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (1): BottleneckBlock(
          (left): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
      )
    )
    (up2): UP(
      (conv): ConvBlock(
        (layers): Sequential(
          (0): ConvINRelu(
            (layers): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): ReLU(inplace=True)
            )
          )
        )
      )
    )
    (att2): ResBlock(
      (layers): Sequential(
        (0): BottleneckBlock(
          (change): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (left): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (1): BottleneckBlock(
          (left): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
      )
    )
    (up1): UP(
      (conv): ConvBlock(
        (layers): Sequential(
          (0): ConvINRelu(
            (layers): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): ReLU(inplace=True)
            )
          )
        )
      )
    )
    (att1): ResBlock(
      (layers): Sequential(
        (0): BottleneckBlock(
          (change): Sequential(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (left): Sequential(
            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (1): BottleneckBlock(
          (left): Sequential(
            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
      )
    )
    (up0): UP(
      (conv): ConvBlock(
        (layers): Sequential(
          (0): ConvINRelu(
            (layers): Sequential(
              (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): ReLU(inplace=True)
            )
          )
        )
      )
    )
    (att0): ResBlock(
      (layers): Sequential(
        (0): BottleneckBlock(
          (change): Sequential(
            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (left): Sequential(
            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (1): BottleneckBlock(
          (left): Sequential(
            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): ReLU(inplace=True)
            (6): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (attention): SEAttention(
            (se): Sequential(
              (0): AdaptiveAvgPool2d(output_size=(1, 1))
              (1): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (2): ReLU(inplace=True)
              (3): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): Sigmoid()
            )
          )
        )
      )
    )
    (Conv_1x1): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (message_layer): Linear(in_features=4096, out_features=64, bias=True)
  )
  (irn): InvNN(
    (operations): ModuleList(
      (0): InvBlock(
        (F): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NF): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (G): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NG): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (H): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NH): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
      )
      (1): InvBlock(
        (F): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NF): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (G): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NG): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (H): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NH): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
      )
      (2): InvBlock(
        (F): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NF): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (G): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NG): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (H): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NH): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
      )
      (3): InvBlock(
        (F): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NF): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (G): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NG): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (H): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NH): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
      )
      (4): InvBlock(
        (F): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NF): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (G): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NG): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (H): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NH): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
      )
      (5): InvBlock(
        (F): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NF): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (G): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NG): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (H): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NH): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
      )
      (6): InvBlock(
        (F): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NF): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (G): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NG): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (H): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NH): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
      )
      (7): InvBlock(
        (F): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NF): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (G): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NG): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (H): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NH): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
      )
      (8): InvBlock(
        (F): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NF): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (G): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NG): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (H): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NH): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
      )
      (9): InvBlock(
        (F): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NF): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (G): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NG): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (H): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NH): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
      )
      (10): InvBlock(
        (F): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NF): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (G): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NG): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (H): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NH): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
      )
      (11): InvBlock(
        (F): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NF): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (G): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NG): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
        (H): DenseBlock(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (NH): NAFBlock(
          (conv1): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
          (conv3): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (sca): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          )
          (sg): SimpleGate()
          (conv4): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
          (conv5): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
          (norm1): LayerNorm2d()
          (norm2): LayerNorm2d()
          (dropout1): Identity()
          (dropout2): Identity()
        )
      )
    )
  )
  (pm): PredictiveModuleMIMO_prompt(
    (conv_in): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (res_block): Sequential(
      (0): ResidualBlockNoBN(
        (conv1): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (relu): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (1): ResidualBlockNoBN(
        (conv1): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (relu): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (2): ResidualBlockNoBN(
        (conv1): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (relu): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (3): ResidualBlockNoBN(
        (conv1): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (relu): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (4): ResidualBlockNoBN(
        (conv1): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (relu): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (5): ResidualBlockNoBN(
        (conv1): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (relu): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (6): ResidualBlockNoBN(
        (conv1): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (relu): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (7): ResidualBlockNoBN(
        (conv1): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (relu): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (transformer_block): Sequential(
      (0): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(12, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=36, bias=False)
          (project_out): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (project_out): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (1): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(12, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=36, bias=False)
          (project_out): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (project_out): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (2): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(12, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=36, bias=False)
          (project_out): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (project_out): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (3): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(12, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=36, bias=False)
          (project_out): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (project_out): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
    )
    (prompt): PromptGenBlock(
      (linear_layer): Linear(in_features=12, out_features=5, bias=True)
      (conv3x3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (fuse): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
24-09-22 17:23:25.067 - WARNING: Params [module.bitencoder.conv1.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.067 - WARNING: Params [module.bitencoder.conv1.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.067 - WARNING: Params [module.bitencoder.conv1.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.067 - WARNING: Params [module.bitencoder.conv1.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.067 - WARNING: Params [module.bitencoder.down1.layer.0.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.067 - WARNING: Params [module.bitencoder.down1.layer.0.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.067 - WARNING: Params [module.bitencoder.down1.layer.1.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.067 - WARNING: Params [module.bitencoder.down1.layer.1.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.067 - WARNING: Params [module.bitencoder.down1.layer.1.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.067 - WARNING: Params [module.bitencoder.down1.layer.1.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.067 - WARNING: Params [module.bitencoder.down2.layer.0.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.067 - WARNING: Params [module.bitencoder.down2.layer.0.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down2.layer.1.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down2.layer.1.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down2.layer.1.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down2.layer.1.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down3.layer.0.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down3.layer.0.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down3.layer.1.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down3.layer.1.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down3.layer.1.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down3.layer.1.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down4.layer.0.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down4.layer.0.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down4.layer.1.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.068 - WARNING: Params [module.bitencoder.down4.layer.1.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.down4.layer.1.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.down4.layer.1.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.up3.conv.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.up3.conv.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.linear3.weight] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.linear3.bias] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.Conv_message3.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.Conv_message3.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.Conv_message3.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.Conv_message3.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.att3.layers.0.change.0.weight] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.att3.layers.0.left.0.weight] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.att3.layers.0.left.3.weight] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.att3.layers.0.left.6.weight] will not optimize.
24-09-22 17:23:25.069 - WARNING: Params [module.bitencoder.att3.layers.0.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.att3.layers.0.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.att3.layers.1.left.0.weight] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.att3.layers.1.left.3.weight] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.att3.layers.1.left.6.weight] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.att3.layers.1.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.att3.layers.1.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.up2.conv.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.up2.conv.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.linear2.weight] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.linear2.bias] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.Conv_message2.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.Conv_message2.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.Conv_message2.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.Conv_message2.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.070 - WARNING: Params [module.bitencoder.att2.layers.0.change.0.weight] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.att2.layers.0.left.0.weight] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.att2.layers.0.left.3.weight] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.att2.layers.0.left.6.weight] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.att2.layers.0.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.att2.layers.0.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.att2.layers.1.left.0.weight] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.att2.layers.1.left.3.weight] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.att2.layers.1.left.6.weight] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.att2.layers.1.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.att2.layers.1.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.up1.conv.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.up1.conv.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.linear1.weight] will not optimize.
24-09-22 17:23:25.071 - WARNING: Params [module.bitencoder.linear1.bias] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.Conv_message1.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.Conv_message1.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.Conv_message1.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.Conv_message1.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.att1.layers.0.change.0.weight] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.att1.layers.0.left.0.weight] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.att1.layers.0.left.3.weight] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.att1.layers.0.left.6.weight] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.att1.layers.0.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.att1.layers.0.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.att1.layers.1.left.0.weight] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.att1.layers.1.left.3.weight] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.att1.layers.1.left.6.weight] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.att1.layers.1.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.072 - WARNING: Params [module.bitencoder.att1.layers.1.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.up0.conv.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.up0.conv.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.linear0.weight] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.linear0.bias] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.Conv_message0.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.Conv_message0.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.Conv_message0.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.Conv_message0.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.att0.layers.0.change.0.weight] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.att0.layers.0.left.0.weight] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.att0.layers.0.left.3.weight] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.att0.layers.0.left.6.weight] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.att0.layers.0.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.073 - WARNING: Params [module.bitencoder.att0.layers.0.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitencoder.att0.layers.1.left.0.weight] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitencoder.att0.layers.1.left.3.weight] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitencoder.att0.layers.1.left.6.weight] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitencoder.att0.layers.1.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitencoder.att0.layers.1.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitencoder.Conv_1x1.weight] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitencoder.Conv_1x1.bias] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitdecoder.conv1.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitdecoder.conv1.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitdecoder.conv1.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitdecoder.conv1.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitdecoder.down1.layer.0.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitdecoder.down1.layer.0.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitdecoder.down1.layer.1.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.074 - WARNING: Params [module.bitdecoder.down1.layer.1.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down1.layer.1.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down1.layer.1.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down2.layer.0.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down2.layer.0.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down2.layer.1.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down2.layer.1.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down2.layer.1.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down2.layer.1.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down3.layer.0.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down3.layer.0.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down3.layer.1.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down3.layer.1.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down3.layer.1.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down3.layer.1.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.075 - WARNING: Params [module.bitdecoder.down4.layer.0.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.down4.layer.0.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.down4.layer.1.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.down4.layer.1.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.down4.layer.1.layers.1.layers.0.weight] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.down4.layer.1.layers.1.layers.0.bias] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.up3.conv.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.up3.conv.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.att3.layers.0.change.0.weight] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.att3.layers.0.left.0.weight] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.att3.layers.0.left.3.weight] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.att3.layers.0.left.6.weight] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.att3.layers.0.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.att3.layers.0.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.att3.layers.1.left.0.weight] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.att3.layers.1.left.3.weight] will not optimize.
24-09-22 17:23:25.076 - WARNING: Params [module.bitdecoder.att3.layers.1.left.6.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.att3.layers.1.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.att3.layers.1.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.up2.conv.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.up2.conv.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.att2.layers.0.change.0.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.att2.layers.0.left.0.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.att2.layers.0.left.3.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.att2.layers.0.left.6.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.att2.layers.0.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.att2.layers.0.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.att2.layers.1.left.0.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.att2.layers.1.left.3.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.att2.layers.1.left.6.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.att2.layers.1.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.att2.layers.1.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.077 - WARNING: Params [module.bitdecoder.up1.conv.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.up1.conv.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.att1.layers.0.change.0.weight] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.att1.layers.0.left.0.weight] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.att1.layers.0.left.3.weight] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.att1.layers.0.left.6.weight] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.att1.layers.0.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.att1.layers.0.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.att1.layers.1.left.0.weight] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.att1.layers.1.left.3.weight] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.att1.layers.1.left.6.weight] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.att1.layers.1.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.att1.layers.1.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.up0.conv.layers.0.layers.0.weight] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.up0.conv.layers.0.layers.0.bias] will not optimize.
24-09-22 17:23:25.078 - WARNING: Params [module.bitdecoder.att0.layers.0.change.0.weight] will not optimize.
24-09-22 17:23:25.079 - WARNING: Params [module.bitdecoder.att0.layers.0.left.0.weight] will not optimize.
24-09-22 17:23:25.079 - WARNING: Params [module.bitdecoder.att0.layers.0.left.3.weight] will not optimize.
24-09-22 17:23:25.079 - WARNING: Params [module.bitdecoder.att0.layers.0.left.6.weight] will not optimize.
24-09-22 17:23:25.079 - WARNING: Params [module.bitdecoder.att0.layers.0.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.079 - WARNING: Params [module.bitdecoder.att0.layers.0.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.079 - WARNING: Params [module.bitdecoder.att0.layers.1.left.0.weight] will not optimize.
24-09-22 17:23:25.079 - WARNING: Params [module.bitdecoder.att0.layers.1.left.3.weight] will not optimize.
24-09-22 17:23:25.079 - WARNING: Params [module.bitdecoder.att0.layers.1.left.6.weight] will not optimize.
24-09-22 17:23:25.079 - WARNING: Params [module.bitdecoder.att0.layers.1.attention.se.1.weight] will not optimize.
24-09-22 17:23:25.079 - WARNING: Params [module.bitdecoder.att0.layers.1.attention.se.3.weight] will not optimize.
24-09-22 17:23:25.079 - WARNING: Params [module.bitdecoder.Conv_1x1.weight] will not optimize.
24-09-22 17:23:25.079 - WARNING: Params [module.bitdecoder.message_layer.weight] will not optimize.
24-09-22 17:23:25.079 - WARNING: Params [module.bitdecoder.message_layer.bias] will not optimize.
24-09-22 17:23:25.084 - INFO: Model [Model_VSN] is created.
24-09-22 17:23:25.084 - INFO: Start training from epoch: 0, iter: 0
